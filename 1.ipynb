{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Introduction to Data Science\n","Homework-01"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Q1)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n","0  LP001002   Male      No          0      Graduate            No   \n","1  LP001003   Male     Yes          1      Graduate            No   \n","2  LP001005   Male     Yes          0      Graduate           Yes   \n","3  LP001006   Male     Yes          0  Not Graduate            No   \n","4  LP001008   Male      No          0      Graduate            No   \n","\n","   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n","0             5849                0.0         NaN             360.0   \n","1             4583             1508.0       128.0             360.0   \n","2             3000                0.0        66.0             360.0   \n","3             2583             2358.0       120.0             360.0   \n","4             6000                0.0       141.0             360.0   \n","\n","   Credit_History Property_Area Loan_Status  \n","0             1.0         Urban           Y  \n","1             1.0         Rural           N  \n","2             1.0         Urban           Y  \n","3             1.0         Urban           Y  \n","4             1.0         Urban           Y  \n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 614 entries, 0 to 613\n","Data columns (total 13 columns):\n"," #   Column             Non-Null Count  Dtype  \n","---  ------             --------------  -----  \n"," 0   Loan_ID            614 non-null    object \n"," 1   Gender             601 non-null    object \n"," 2   Married            611 non-null    object \n"," 3   Dependents         599 non-null    object \n"," 4   Education          614 non-null    object \n"," 5   Self_Employed      582 non-null    object \n"," 6   ApplicantIncome    614 non-null    int64  \n"," 7   CoapplicantIncome  614 non-null    float64\n"," 8   LoanAmount         592 non-null    float64\n"," 9   Loan_Amount_Term   600 non-null    float64\n"," 10  Credit_History     564 non-null    float64\n"," 11  Property_Area      614 non-null    object \n"," 12  Loan_Status        614 non-null    object \n","dtypes: float64(4), int64(1), object(8)\n","memory usage: 62.5+ KB\n","None\n","       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n","count       614.000000         614.000000  592.000000         600.00000   \n","mean       5403.459283        1621.245798  146.412162         342.00000   \n","std        6109.041673        2926.248369   85.587325          65.12041   \n","min         150.000000           0.000000    9.000000          12.00000   \n","25%        2877.500000           0.000000  100.000000         360.00000   \n","50%        3812.500000        1188.500000  128.000000         360.00000   \n","75%        5795.000000        2297.250000  168.000000         360.00000   \n","max       81000.000000       41667.000000  700.000000         480.00000   \n","\n","       Credit_History  \n","count      564.000000  \n","mean         0.842199  \n","std          0.364878  \n","min          0.000000  \n","25%          1.000000  \n","50%          1.000000  \n","75%          1.000000  \n","max          1.000000  \n"]}],"source":["# a\n","import pandas as pd\n","loan_data = pd.read_csv('loan.csv')\n","\n","print(loan_data.head())\n","print(loan_data.info())\n","print(loan_data.describe())\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# b.\n","\n","1)\tMissing at Random (MAR): The missing values depend on other observed values such as income may be missing for some people because they are unemployed.\n","\n","2)\tMissing Completely at Random (MCAR): The missing values are unrelated to other observed or unobserved values such as data entry errors.\n","\n","3)\tMissing Not at Random (MNAR): The missing values depend on unobserved values such as people with high debt may not report their debt.\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loan_ID               0\n","Gender               13\n","Married               3\n","Dependents           15\n","Education             0\n","Self_Employed        32\n","ApplicantIncome       0\n","CoapplicantIncome     0\n","LoanAmount           22\n","Loan_Amount_Term     14\n","Credit_History       50\n","Property_Area         0\n","Loan_Status           0\n","dtype: int64\n","Total missing values: 149\n"]}],"source":["# c.\n","missing_values = loan_data.isna().sum()\n","total_missing_values = missing_values.sum()\n","print(missing_values)\n","print(\"Total missing values:\", total_missing_values)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# d.\n","1)\tDeletion: Remove rows or columns with missing values.\n","2)\tImputation: Fill missing values with estimates based on other available data.\n","3)\tModel-based methods: Use statistical models to account for missing data during analysis."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original dataset:\n","       Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n","0    LP001002    Male      No          0      Graduate            No   \n","1    LP001003    Male     Yes          1      Graduate            No   \n","2    LP001005    Male     Yes          0      Graduate           Yes   \n","3    LP001006    Male     Yes          0  Not Graduate            No   \n","4    LP001008    Male      No          0      Graduate            No   \n","..        ...     ...     ...        ...           ...           ...   \n","609  LP002978  Female      No          0      Graduate            No   \n","610  LP002979    Male     Yes         3+      Graduate            No   \n","611  LP002983    Male     Yes          1      Graduate            No   \n","612  LP002984    Male     Yes          2      Graduate            No   \n","613  LP002990  Female      No          0      Graduate           Yes   \n","\n","     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n","0               5849                0.0         NaN             360.0   \n","1               4583             1508.0       128.0             360.0   \n","2               3000                0.0        66.0             360.0   \n","3               2583             2358.0       120.0             360.0   \n","4               6000                0.0       141.0             360.0   \n","..               ...                ...         ...               ...   \n","609             2900                0.0        71.0             360.0   \n","610             4106                0.0        40.0             180.0   \n","611             8072              240.0       253.0             360.0   \n","612             7583                0.0       187.0             360.0   \n","613             4583                0.0       133.0             360.0   \n","\n","     Credit_History Property_Area Loan_Status  \n","0               1.0         Urban           Y  \n","1               1.0         Rural           N  \n","2               1.0         Urban           Y  \n","3               1.0         Urban           Y  \n","4               1.0         Urban           Y  \n","..              ...           ...         ...  \n","609             1.0         Rural           Y  \n","610             1.0         Rural           Y  \n","611             1.0         Urban           Y  \n","612             1.0         Urban           Y  \n","613             0.0     Semiurban           N  \n","\n","[614 rows x 13 columns]\n","Mean imputed dataset:\n","       Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n","0    LP001002    Male      No          0      Graduate            No   \n","1    LP001003    Male     Yes          1      Graduate            No   \n","2    LP001005    Male     Yes          0      Graduate           Yes   \n","3    LP001006    Male     Yes          0  Not Graduate            No   \n","4    LP001008    Male      No          0      Graduate            No   \n","..        ...     ...     ...        ...           ...           ...   \n","609  LP002978  Female      No          0      Graduate            No   \n","610  LP002979    Male     Yes         3+      Graduate            No   \n","611  LP002983    Male     Yes          1      Graduate            No   \n","612  LP002984    Male     Yes          2      Graduate            No   \n","613  LP002990  Female      No          0      Graduate           Yes   \n","\n","     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n","0             5849.0                0.0  146.412162             360.0   \n","1             4583.0             1508.0  128.000000             360.0   \n","2             3000.0                0.0   66.000000             360.0   \n","3             2583.0             2358.0  120.000000             360.0   \n","4             6000.0                0.0  141.000000             360.0   \n","..               ...                ...         ...               ...   \n","609           2900.0                0.0   71.000000             360.0   \n","610           4106.0                0.0   40.000000             180.0   \n","611           8072.0              240.0  253.000000             360.0   \n","612           7583.0                0.0  187.000000             360.0   \n","613           4583.0                0.0  133.000000             360.0   \n","\n","     Credit_History Property_Area Loan_Status  \n","0               1.0         Urban           Y  \n","1               1.0         Rural           N  \n","2               1.0         Urban           Y  \n","3               1.0         Urban           Y  \n","4               1.0         Urban           Y  \n","..              ...           ...         ...  \n","609             1.0         Rural           Y  \n","610             1.0         Rural           Y  \n","611             1.0         Urban           Y  \n","612             1.0         Urban           Y  \n","613             0.0     Semiurban           N  \n","\n","[614 rows x 13 columns]\n","Median imputed dataset:\n","       Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n","0    LP001002    Male      No          0      Graduate            No   \n","1    LP001003    Male     Yes          1      Graduate            No   \n","2    LP001005    Male     Yes          0      Graduate           Yes   \n","3    LP001006    Male     Yes          0  Not Graduate            No   \n","4    LP001008    Male      No          0      Graduate            No   \n","..        ...     ...     ...        ...           ...           ...   \n","609  LP002978  Female      No          0      Graduate            No   \n","610  LP002979    Male     Yes         3+      Graduate            No   \n","611  LP002983    Male     Yes          1      Graduate            No   \n","612  LP002984    Male     Yes          2      Graduate            No   \n","613  LP002990  Female      No          0      Graduate           Yes   \n","\n","     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n","0             5849.0                0.0       128.0             360.0   \n","1             4583.0             1508.0       128.0             360.0   \n","2             3000.0                0.0        66.0             360.0   \n","3             2583.0             2358.0       120.0             360.0   \n","4             6000.0                0.0       141.0             360.0   \n","..               ...                ...         ...               ...   \n","609           2900.0                0.0        71.0             360.0   \n","610           4106.0                0.0        40.0             180.0   \n","611           8072.0              240.0       253.0             360.0   \n","612           7583.0                0.0       187.0             360.0   \n","613           4583.0                0.0       133.0             360.0   \n","\n","     Credit_History Property_Area Loan_Status  \n","0               1.0         Urban           Y  \n","1               1.0         Rural           N  \n","2               1.0         Urban           Y  \n","3               1.0         Urban           Y  \n","4               1.0         Urban           Y  \n","..              ...           ...         ...  \n","609             1.0         Rural           Y  \n","610             1.0         Rural           Y  \n","611             1.0         Urban           Y  \n","612             1.0         Urban           Y  \n","613             0.0     Semiurban           N  \n","\n","[614 rows x 13 columns]\n","Mode imputed dataset:\n","       Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n","0    LP001002    Male      No          0      Graduate            No   \n","1    LP001003    Male     Yes          1      Graduate            No   \n","2    LP001005    Male     Yes          0      Graduate           Yes   \n","3    LP001006    Male     Yes          0  Not Graduate            No   \n","4    LP001008    Male      No          0      Graduate            No   \n","..        ...     ...     ...        ...           ...           ...   \n","609  LP002978  Female      No          0      Graduate            No   \n","610  LP002979    Male     Yes         3+      Graduate            No   \n","611  LP002983    Male     Yes          1      Graduate            No   \n","612  LP002984    Male     Yes          2      Graduate            No   \n","613  LP002990  Female      No          0      Graduate           Yes   \n","\n","     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n","0               5849                0.0         NaN             360.0   \n","1               4583             1508.0       128.0             360.0   \n","2               3000                0.0        66.0             360.0   \n","3               2583             2358.0       120.0             360.0   \n","4               6000                0.0       141.0             360.0   \n","..               ...                ...         ...               ...   \n","609             2900                0.0        71.0             360.0   \n","610             4106                0.0        40.0             180.0   \n","611             8072              240.0       253.0             360.0   \n","612             7583                0.0       187.0             360.0   \n","613             4583                0.0       133.0             360.0   \n","\n","     Credit_History Property_Area Loan_Status  \n","0               1.0         Urban           Y  \n","1               1.0         Rural           N  \n","2               1.0         Urban           Y  \n","3               1.0         Urban           Y  \n","4               1.0         Urban           Y  \n","..              ...           ...         ...  \n","609             1.0         Rural           Y  \n","610             1.0         Rural           Y  \n","611             1.0         Urban           Y  \n","612             1.0         Urban           Y  \n","613             0.0     Semiurban           N  \n","\n","[614 rows x 13 columns]\n","Constant imputed dataset:\n","       Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n","0    LP001002    Male      No          0      Graduate            No   \n","1    LP001003    Male     Yes          1      Graduate            No   \n","2    LP001005    Male     Yes          0      Graduate           Yes   \n","3    LP001006    Male     Yes          0  Not Graduate            No   \n","4    LP001008    Male      No          0      Graduate            No   \n","..        ...     ...     ...        ...           ...           ...   \n","609  LP002978  Female      No          0      Graduate            No   \n","610  LP002979    Male     Yes         3+      Graduate            No   \n","611  LP002983    Male     Yes          1      Graduate            No   \n","612  LP002984    Male     Yes          2      Graduate            No   \n","613  LP002990  Female      No          0      Graduate           Yes   \n","\n","     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n","0               5849                0.0         NaN             360.0   \n","1               4583             1508.0       128.0             360.0   \n","2               3000                0.0        66.0             360.0   \n","3               2583             2358.0       120.0             360.0   \n","4               6000                0.0       141.0             360.0   \n","..               ...                ...         ...               ...   \n","609             2900                0.0        71.0             360.0   \n","610             4106                0.0        40.0             180.0   \n","611             8072              240.0       253.0             360.0   \n","612             7583                0.0       187.0             360.0   \n","613             4583                0.0       133.0             360.0   \n","\n","     Credit_History Property_Area Loan_Status  \n","0               1.0         Urban           Y  \n","1               1.0         Rural           N  \n","2               1.0         Urban           Y  \n","3               1.0         Urban           Y  \n","4               1.0         Urban           Y  \n","..              ...           ...         ...  \n","609             1.0         Rural           Y  \n","610             1.0         Rural           Y  \n","611             1.0         Urban           Y  \n","612             1.0         Urban           Y  \n","613             0.0     Semiurban           N  \n","\n","[614 rows x 13 columns]\n"]}],"source":["# e\n","from sklearn.impute import SimpleImputer\n","import numpy as np\n","\n","# Separate numeric and categorical columns\n","numeric_columns = loan_data.select_dtypes(include=np.number).columns\n","categorical_columns = loan_data.select_dtypes(exclude=np.number).columns\n","\n","# Imputing missing values for numeric columns:\n","# Mean imputation\n","mean_imputer = SimpleImputer(strategy='mean')\n","loan_data_mean = loan_data.copy()\n","loan_data_mean[numeric_columns] = mean_imputer.fit_transform(loan_data_mean[numeric_columns])\n","\n","\n","# Median imputation\n","median_imputer = SimpleImputer(strategy='median')\n","loan_data_median = loan_data.copy()\n","loan_data_median[numeric_columns] = median_imputer.fit_transform(loan_data_median[numeric_columns])\n","\n","\n","# Imputing missing values for categorical columns\n","# mode\n","mode_imputer = SimpleImputer(strategy='most_frequent')\n","loan_data_mode = loan_data.copy()\n","loan_data_mode[categorical_columns] = mode_imputer.fit_transform(loan_data_mode[categorical_columns])\n","\n","# constant or unknown\n","constant_imputer = SimpleImputer(strategy='constant', fill_value='Unknown')\n","loan_data_constant = loan_data.copy()\n","loan_data_constant[categorical_columns] = constant_imputer.fit_transform(loan_data_constant[categorical_columns])\n","\n","print(\"Original dataset:\\n\", loan_data)\n","print(\"Mean imputed dataset:\\n\", loan_data_mean)\n","print(\"Median imputed dataset:\\n\", loan_data_median)\n","print(\"Mode imputed dataset:\\n\", loan_data_mode)\n","print(\"Constant imputed dataset:\\n\", loan_data_constant)\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Q2. A model becomes unidentifiable when it is impossible to determine unique predictions for some of its parameters, even with an infinite amount of data. This typically occurs in situations where it has too many parameters compared to the amount of available data.\n","\n","Ways of Handling:\n","\n","1- Regularization such as Lasso (L1) and Ridge (L2) regularization.\n","2- Obtaining more data.\n","3- Reducing the number of parameters.\n","4- Transforming variablessuch as through scaling, centering, or applying mathematical functions like log or square root which can help resolve multicollinearity and improve model identifiability.\n","5- Using a simpler model.\n","6- Combining correlated variables using techniques like PCA.\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Principal Components:\n"," [[ 0.70710678 -0.70710678]\n"," [ 0.70710678  0.70710678]]\n","Projected Data:\n"," [[ 1.55395282 -0.07706147]\n"," [-1.8780133   0.1739079 ]\n"," [-0.75635008  0.0065437 ]\n"," [ 2.21524911  0.21594127]\n"," [ 0.36531314 -0.1608205 ]\n"," [-1.52226822 -0.02278734]\n"," [ 0.02211653 -0.13572356]]\n"]}],"source":["# Q3\n","\n","# Making the dataset standard\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","\n","X = np.array([[2.8, 2.7],\n","              [0.8, 0.7],\n","              [1.5, 1.3],\n","              [3.0, 3.3],\n","              [2.2, 1.9],\n","              [1.1, 0.8],\n","              [2.0, 1.7]])\n","\n","scaler = StandardScaler()\n","X_standardized = scaler.fit_transform(X)\n","\n","\n","# covariance matrix\n","cov_matrix = np.cov(X_standardized.T)\n","eigenvalues, eigenvectors = np.linalg.eig(cov_matrix) # eigenvalues and eigenvectors\n","\n","\n","# Sort Desc\n","sorted_indices = np.argsort(eigenvalues)[::-1]\n","eigenvalues_sorted = eigenvalues[sorted_indices]\n","eigenvectors_sorted = eigenvectors[:, sorted_indices]\n","\n","\n","# we only have 2 variables\n","k = 2\n","principal_components = eigenvectors_sorted[:, :k]\n","\n","# results\n","print(\"Principal Components:\\n\", principal_components)\n","\n","# projecting the original standard data onto the new principal component axes\n","X_projected = np.dot(X_standardized, principal_components)\n","print(\"Projected Data:\\n\", X_projected)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Top 10 features (index): [ 31  30  29  28  38 103 105 106 107 102]\n"]}],"source":["# Q4.\n","# a.\n","# CensusIncome Dataset from UCI Machine Learning Repository: It has about 32561 records and a mix of categorical and continuous features.\n","# b.\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.compose import ColumnTransformer\n","from sklearn.feature_selection import SelectKBest, chi2\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LassoCV\n","from sklearn.model_selection import train_test_split\n","\n","#load the dataset\n","data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n","column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'target']\n","dataset = pd.read_csv(data_url, names=column_names)\n","\n","# Preprocessing: Separate target variable and drop it from the dataset\n","target = dataset['target']\n","dataset = dataset.drop(columns=['target'])\n","\n","# Encode the target variable\n","le = LabelEncoder()\n","target_encoded = le.fit_transform(target)\n","\n","# identify categorical columns\n","categorical_columns = dataset.select_dtypes(include='object').columns\n","\n","# one-hot encoding for categorical features\n","preprocessor = ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)], remainder='passthrough')\n","X_transformed = preprocessor.fit_transform(dataset)\n","\n","# Feature selection with Lasso\n","X_train, X_test, y_train, y_test = train_test_split(X_transformed, target_encoded, test_size=0.2, random_state=42)\n","lasso = LassoCV(cv=5, random_state=42).fit(X_train, y_train)\n","\n","# Get the top 10 features\n","coef = lasso.coef_\n","top_10_features = np.argsort(np.abs(coef))[-10:]\n","print(\"Top 10 features (index):\", top_10_features)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["c.\n","In the presented solution, we use the Census Income Dataset as an example to demonstrate feature selection in a large-scale dataset with categorical variables. The approach aims to handle mixed data types by preprocessing categorical data using one-hot encoding, which is a necessary step as PCA and Lasso methods cannot directly handle categorical data.\n","\n","We employ Lasso regularization for feature selection since it's more suitable for a mix of categorical and continuous features, as opposed to PCA which is generally more appropriate for continuous data. After preprocessing the dataset and applying one-hot encoding, we split it into training and testing sets and train a LassoCV model with 5-fold cross-validation on the training set.\n","\n","Once the model is trained, we identify the top 10 features with the highest absolute coefficients, indicating the strongest correlation with the target variable. The solution focuses on implementing a pipeline for preprocessing and feature selection in large-scale datasets with mixed data types, using Lasso regularization as the primary technique for dimensionality reduction and feature selection."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Q5) The typical Data Science process is often referred to as the \"Cross-Industry Standard Process for Data Mining\" (CRISP-DM). It consists of the following six stages:\n","\n","1. Business Understanding\n","2. Data Understanding\n","3. Data Preparation\n","4. Modeling\n","5. Evaluation\n","6. Deployment\n","\n","![Alt text](drawings.png)\n","\n","Explanation:\n","*) Business Understanding: This initial phase focuses on understanding the project's objectives, requirements, and the problem domain. It involves close collaboration with stakeholders and domain experts to identify the goals and define the scope of the project.\n","*) Data Understanding: In this phase, data scientists explore and familiarize themselves with the available data. They assess the quality of the data, its relevance to the problem, and any potential issues that might require further attention during data preparation.\n","*) Data Preparation: This stage involves cleaning, preprocessing, and transforming the data to make it suitable for analysis and modeling. Typical tasks include handling missing values, encoding categorical variables, feature engineering, and data normalization or scaling.\n","*) Modeling: During this phase, data scientists develop and train various machine learning or statistical models using the prepared data. They select appropriate algorithms, configure their parameters, and evaluate the performance of each model to find the one that best fits the problem.\n","*) Evaluation: In this stage, the chosen models are rigorously evaluated using various metrics to ensure their quality, reliability, and suitability for addressing the business objectives. This phase helps determine if the models are meeting the desired performance criteria or if further refinement is needed.\n","*) Deployment: Once the models have been evaluated and deemed satisfactory, they are deployed into production environments to generate insights, make predictions, or inform decision-making processes. The deployment phase also includes monitoring the performance of the models and updating them as needed.\n","In fact, its process is iterative, and it is common to revisit earlier stages as new insights are gained or requirements change. Each project may have unique requirements and may require adaptation or customization of the process to best fit the specific problem domain.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Q6.\n","a. Problem Statement:\n","Predicting the severity of road accidents to enable better emergency response and reduce fatalities.\n","\n","Road accidents are a major concern in urban areas, often resulting in severe injuries or fatalities. The severity of these accidents depends on various factors, such as weather conditions, road conditions, speed, and time of day. Predicting the severity of road accidents can help emergency responders allocate resources more efficiently, potentially saving lives and reducing the impact of accidents on traffic flow.\n","\n","b. Dataset:\n","The dataset used for this problem is the \"US Accidents\" dataset available on Kaggle (https://www.kaggle.com/sobhanmoosavi/us-accidents). This dataset contains information about 3 million road accidents in the United States from 2016 to 2020. It includes various features such as location, time, weather conditions, and road conditions.\n","\n","c. Sample data:\n","\n","ID    Source     TMC      Severity     Start_Time             End_Time              ...\n","A-1   MapQuest   201      3            2016-02-08 05:46:00    2016-02-08 11:00:00   ...\n","A-2   MapQuest   201      2            2016-02-08 06:07:59    2016-02-08 06:37:59   ...\n","A-3   MapQuest   201      2            2016-02-08 06:49:27    2016-02-08 07:19:27   ...\n","\n","\n","d. Essay:\n","Road accidents can have devastating consequences on people's lives, leading to injuries, fatalities, and disruptions to traffic flow. Predicting the severity of road accidents is crucial in order to provide timely and efficient emergency response, ultimately reducing the number of casualties and minimizing traffic congestion.\n","\n","Data scientists have been able to address this problem by leveraging the power of machine learning and data analysis techniques. By using a comprehensive dataset containing information about millions of road accidents in the United States, they have been able to identify patterns and relationships between different factors that influence the severity of accidents.\n","\n","First, the dataset was preprocessed and cleaned to remove any inconsistencies or missing values. Next, exploratory data analysis was conducted to gain a better understanding of the data, identifying correlations and trends between different features, such as weather conditions, road conditions, and time of day. This information allowed the data scientists to select the most relevant features for building a predictive model. Once the relevant features were selected, several machine learning algorithms, such as decision trees, logistic regression, and random forests, were tested to find the best model for predicting accident severity. By training these models on a portion of the dataset and validating their performance on unseen data, the data scientists were able to assess the accuracy and reliability of each model. Ultimately, the best-performing model was chosen and fine-tuned to maximize its predictive capabilities. This model can now be used by emergency responders to anticipate the severity of road accidents in real-time, allowing them to allocate resources more effectively, potentially saving lives and reducing the impact of accidents on traffic flow.\n","\n","In conclusion, data science has played a pivotal role in addressing the issue of road accident severity prediction. By harnessing the power of machine learning and data analysis, data scientists have been able to develop a valuable tool that can help save lives and minimize the disruption caused by road accidents."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Q7.\n","\n","a. Distinctions between clean data and dirty data:\n","\n","In fact, clean data refers to data that is accurate, consistent, and free of errors or anomalies. This data is well-formatted, correctly labeled, and ready for analysis. Dirty data, on the other hand, is data containing errors, inconsistencies, or missing values that can hinder the data analysis process and lead to inaccurate conclusions.\n","\n","Handling method:\n","\n","1. Impute missing values: Replace missing values with the mean, median, or mode of the data, or use more advanced techniques like k-nearest neighbors or regression imputation.\n","2. Remove duplicates: Identify and remove any duplicate records in the dataset.\n","3. Outlier detection and removal: Identify and remove outliers that may skew the analysis or negatively impact the performance of machine learning models.\n","4. Feature scaling: Standardize or normalize the features to ensure they are on a similar scale, which can improve the performance of some machine learning algorithms.\n","5. Data transformation: Apply transformations like logarithmic or power transformations to reduce the impact of noise or make the data more suitable for analysis.\n","\n","\n","b.\n","\n","ID\t Name\t         Street\t \t\t\t\tCity\t \t State\tZip\t \tHours\n","1\t Jacob Meltzer\t 123 University Ave\t \tProvidence\t RI\t\t2906\t42\n","2\t Erin Bugbee\t 245 Third St\t \t\tPawtucket\t RI\t\t2860\t30\n","3\t David Wang\t     345 Broadway\t \t\tProvidence\t RI\t\t2903\t19\n","4\t Erin Bugbee\t 245 Third St\t \t\tPawtucket\t RI\t\t2860\t29\n","5\t David Wang\t \t 345 Broadway\t \t\tProvidence\t RI\t\t2903\t19\n","6\t Jacob Meltzer\t 123 University Ave\t \tProvidence\t RI\t\t2906\t41\n","7\t Haomo Ni\t     123 University Ave\t \tProvidence\t RI\t\t2906\t0\n","\n","\n","\n","Standardized the city names (\"PVD\" to \"Providence\", \"Providnce\" to \"Providence\").\n","Standardized the street names (\"3ra St\" to \"Third St\", \"University Ave\" to \"University Ave\", \"Broadway St\" to \"Broadway\").\n","Fixed the state abbreviation for Rhode Island (\"Rhode Island\" to \"RI\").\n","Corrected the zip codes for records 2, 4, and 6.\n","Fixed the name of record 4 (E Bugbe to Erin Bugbee) and updated the hours to 29 (assuming it was a typo).\n","Removed the incorrect country from record 7 (Guyana).\n","Replaced NULL values with appropriate missing value indicators (e.g., np.nan in Python)."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["A new era of twitter is going to start Twitter will lead the tech world from now on.Yeah..\n","Area Code: 541, Exchange: 471, Line Number: 3918\n","Area Code: 603, Exchange: 281, Line Number: 0308\n","Area Code: 814, Exchange: 462, Line Number: 8074\n","Area Code: 970, Exchange: 444, Line Number: 3106\n"]}],"source":["# Q8\n","# a\n","import re\n","\n","text1 = \"@A new era of twitter is going to start?!! Twitter will lead the tech world from now on.Yeah..!!\"\n","cleaned_text = re.sub(r\"[^a-zA-Z0-9\\s\\.]+\", \"\", text1)\n","\n","print(cleaned_text)\n","\n","# b\n","import re\n","\n","phone_numbers = [\n","    \"(541) 471 3918\",\n","    \"(603)281-0308\",\n","    \"(814)-462-8074\",\n","    \"9704443106\"\n","]\n","\n","pattern = re.compile(r\"\\(?(\\d{3})\\)?[-\\s]?(\\d{3})[-\\s]?(\\d{4})\")\n","\n","for number in phone_numbers:\n","    match = pattern.match(number)\n","    if match:\n","        area_code, exchange, line_number = match.groups()\n","        print(f\"Area Code: {area_code}, Exchange: {exchange}, Line Number: {line_number}\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["       Unnamed: 0  store type  department        date  weekly_sales  \\\n","10767       10767     39    A          99  2011-08-19        622.00   \n","10768       10768     39    A          99  2011-11-11         50.00   \n","10769       10769     39    A          99  2011-12-09        895.00   \n","10770       10770     39    A          99  2012-02-03        350.00   \n","10771       10771     39    A          99  2012-06-08        450.00   \n","10772       10772     39    A          99  2012-07-13          0.06   \n","10773       10773     39    A          99  2012-10-05        915.00   \n","\n","       is_holiday  temperature_c  fuel_price_usd_per_l  unemployment  \n","10767       False      31.072222              0.938868         8.177  \n","10768       False      17.283333              0.870976         7.716  \n","10769       False       9.644444              0.834256         7.716  \n","10770       False      15.938889              0.887619         7.244  \n","10771       False      27.288889              0.911922         6.989  \n","10772       False      25.644444              0.860145         6.623  \n","10773       False      22.250000              0.955511         6.228  \n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10774 entries, 0 to 10773\n","Data columns (total 10 columns):\n"," #   Column                Non-Null Count  Dtype  \n","---  ------                --------------  -----  \n"," 0   Unnamed: 0            10774 non-null  int64  \n"," 1   store                 10774 non-null  int64  \n"," 2   type                  10774 non-null  object \n"," 3   department            10774 non-null  int64  \n"," 4   date                  10774 non-null  object \n"," 5   weekly_sales          10774 non-null  float64\n"," 6   is_holiday            10774 non-null  bool   \n"," 7   temperature_c         10774 non-null  float64\n"," 8   fuel_price_usd_per_l  10774 non-null  float64\n"," 9   unemployment          10774 non-null  float64\n","dtypes: bool(1), float64(4), int64(3), object(2)\n","memory usage: 768.2+ KB\n","None\n","         Unnamed: 0         store    department   weekly_sales  temperature_c  \\\n","count  10774.000000  10774.000000  10774.000000   10774.000000   10774.000000   \n","mean    5386.500000     15.441897     45.218118   23843.950149      15.731978   \n","std     3110.330234     11.534511     29.867779   30220.387557       9.922446   \n","min        0.000000      1.000000      1.000000   -1098.000000      -8.366667   \n","25%     2693.250000      4.000000     20.000000    3867.115000       7.583333   \n","50%     5386.500000     13.000000     40.000000   12049.065000      16.966667   \n","75%     8079.750000     20.000000     72.000000   32349.850000      24.166667   \n","max    10773.000000     39.000000     99.000000  293966.050000      33.827778   \n","\n","       fuel_price_usd_per_l  unemployment  \n","count          10774.000000  10774.000000  \n","mean               0.749746      8.082009  \n","std                0.059494      0.624355  \n","min                0.664129      3.879000  \n","25%                0.708246      7.795000  \n","50%                0.743381      8.099000  \n","75%                0.781421      8.360000  \n","max                1.107674      9.765000  \n","[[0 1 'A' ... 5.727777777777779 0.6794508388787476 8.106]\n"," [1 1 'A' ... 8.055555555555555 0.693451964252221 8.106]\n"," [2 1 'A' ... 16.81666666666667 0.718284148876872 7.808]\n"," ...\n"," [10771 39 'A' ... 27.28888888888889 0.911922354513778 6.989]\n"," [10772 39 'A' ... 25.64444444444444 0.8601446078496121 6.622999999999999]\n"," [10773 39 'A' ... 22.25 0.955510763695346 6.228]]\n","       Unnamed: 0  store type  department        date  weekly_sales  \\\n","4379         4379     10    B          87  2010-06-04      19530.92   \n","3976         3976     10    B          33  2011-01-07      10566.11   \n","3974         3974     10    B          33  2010-11-05      12468.98   \n","3973         3973     10    B          33  2010-10-01       8663.69   \n","3972         3972     10    B          33  2010-09-03       9555.57   \n","...           ...    ...  ...         ...         ...           ...   \n","3291         3291      6    A          56  2010-06-04       7515.90   \n","3292         3292      6    A          56  2010-07-02       4149.20   \n","3293         3293      6    A          56  2010-08-06       1639.70   \n","3294         3294      6    A          56  2010-09-03       2172.08   \n","10773       10773     39    A          99  2012-10-05        915.00   \n","\n","       is_holiday  temperature_c  fuel_price_usd_per_l  unemployment  \n","4379        False      28.233333              0.776930         9.524  \n","3976        False       6.350000              0.868334         8.744  \n","3974        False      21.688889              0.794894         9.003  \n","3973        False      30.005556              0.792781         9.003  \n","3972        False      28.777778              0.815500         9.199  \n","...           ...            ...                   ...           ...  \n","3291        False      26.355556              0.714586         7.092  \n","3292        False      26.855556              0.705076         6.973  \n","3293        False      30.338889              0.693980         6.973  \n","3294        False      27.861111              0.680772         6.973  \n","10773       False      22.250000              0.955511         6.228  \n","\n","[10774 rows x 10 columns]\n","       Unnamed: 0  store type  department        date  weekly_sales  \\\n","2               2      1    A           1  2010-04-02      57258.43   \n","3               3      1    A           1  2010-05-07      17413.94   \n","4               4      1    A           1  2010-06-04      17558.09   \n","5               5      1    A           1  2010-07-02      16333.14   \n","9               9      1    A           1  2010-11-05      34238.88   \n","...           ...    ...  ...         ...         ...           ...   \n","10769       10769     39    A          99  2011-12-09        895.00   \n","10770       10770     39    A          99  2012-02-03        350.00   \n","10771       10771     39    A          99  2012-06-08        450.00   \n","10772       10772     39    A          99  2012-07-13          0.06   \n","10773       10773     39    A          99  2012-10-05        915.00   \n","\n","       is_holiday  temperature_c  fuel_price_usd_per_l  unemployment  \n","2           False      16.816667              0.718284         7.808  \n","3           False      22.527778              0.748928         7.808  \n","4           False      27.050000              0.714586         7.808  \n","5           False      27.172222              0.705076         7.787  \n","9           False      14.855556              0.710359         7.838  \n","...           ...            ...                   ...           ...  \n","10769       False       9.644444              0.834256         7.716  \n","10770       False      15.938889              0.887619         7.244  \n","10771       False      27.288889              0.911922         6.989  \n","10772       False      25.644444              0.860145         6.623  \n","10773       False      22.250000              0.955511         6.228  \n","\n","[8671 rows x 10 columns]\n","      Unnamed: 0  store type  department        date  weekly_sales  \\\n","4092        4092     10    B          45  2010-09-10         31.41   \n","4295        4295     10    B          77  2011-11-25       1590.00   \n","\n","      is_holiday  temperature_c  fuel_price_usd_per_l  unemployment  \n","4092        True      28.911111              0.782214         9.199  \n","4295        True      15.933333              0.993287         7.874  \n","       Unnamed: 0  store type  department        date  weekly_sales  \\\n","0               0      1    A           1  2010-02-05      24924.50   \n","1               1      1    A           1  2010-03-05      21827.90   \n","2               2      1    A           1  2010-04-02      57258.43   \n","3               3      1    A           1  2010-05-07      17413.94   \n","4               4      1    A           1  2010-06-04      17558.09   \n","...           ...    ...  ...         ...         ...           ...   \n","10769       10769     39    A          99  2011-12-09        895.00   \n","10770       10770     39    A          99  2012-02-03        350.00   \n","10771       10771     39    A          99  2012-06-08        450.00   \n","10772       10772     39    A          99  2012-07-13          0.06   \n","10773       10773     39    A          99  2012-10-05        915.00   \n","\n","       is_holiday  temperature_c  fuel_price_usd_per_l  unemployment  \\\n","0           False       5.727778              0.679451         8.106   \n","1           False       8.055556              0.693452         8.106   \n","2           False      16.816667              0.718284         7.808   \n","3           False      22.527778              0.748928         7.808   \n","4           False      27.050000              0.714586         7.808   \n","...           ...            ...                   ...           ...   \n","10769       False       9.644444              0.834256         7.716   \n","10770       False      15.938889              0.887619         7.244   \n","10771       False      27.288889              0.911922         6.989   \n","10772       False      25.644444              0.860145         6.623   \n","10773       False      22.250000              0.955511         6.228   \n","\n","       amount_of_sales(gallon)  \n","0                 36683.301534  \n","1                 31477.162262  \n","2                 79715.569513  \n","3                 23251.817501  \n","4                 24571.005348  \n","...                        ...  \n","10769              1072.812524  \n","10770               394.313542  \n","10771               493.463065  \n","10772                 0.069756  \n","10773               957.603027  \n","\n","[10774 rows x 11 columns]\n","       Unnamed: 0  store type  department        date  weekly_sales  \\\n","0               0      1    A           1  2010-02-05      24924.50   \n","2               2      1    A           1  2010-04-02      57258.43   \n","9               9      1    A           1  2010-11-05      34238.88   \n","12             12      1    A           2  2010-02-05      50605.27   \n","13             13      1    A           2  2010-03-05      48397.98   \n","...           ...    ...  ...         ...         ...           ...   \n","10732       10732     39    A          96  2010-07-02      30060.32   \n","10733       10733     39    A          96  2010-08-06      26359.08   \n","10734       10734     39    A          96  2010-09-03      26501.74   \n","10735       10735     39    A          96  2010-10-01      25440.22   \n","10746       10746     39    A          97  2010-09-03      26882.38   \n","\n","       is_holiday  temperature_c  fuel_price_usd_per_l  unemployment  \\\n","0           False       5.727778              0.679451         8.106   \n","2           False      16.816667              0.718284         7.808   \n","9           False      14.855556              0.710359         7.838   \n","12          False       5.727778              0.679451         8.106   \n","13          False       8.055556              0.693452         8.106   \n","...           ...            ...                   ...           ...   \n","10732       False      27.416667              0.705076         8.360   \n","10733       False      29.400000              0.693980         8.360   \n","10734       False      27.850000              0.680772         8.360   \n","10735       False      22.633333              0.687640         8.476   \n","10746       False      27.850000              0.680772         8.360   \n","\n","       amount_of_sales(gallon)  \n","0                 36683.301534  \n","2                 79715.569513  \n","9                 48199.404515  \n","12                74479.663729  \n","13                69792.837132  \n","...                        ...  \n","10732             42634.183564  \n","10733             37982.460991  \n","10734             38928.968418  \n","10735             36996.413058  \n","10746             39488.098594  \n","\n","[3146 rows x 11 columns]\n"]}],"source":["# Q9\n","import pandas as pd\n","import numpy as np\n","\n","CircleK_sales = pd.read_csv(\"sales_subset .csv\")\n","\n","# a\n","print(CircleK_sales.tail(7))\n","\n","# b\n","print(CircleK_sales.info())\n","\n","# c\n","print(CircleK_sales.describe())\n","\n","# d\n","numpy_array = np.array(CircleK_sales)\n","print(numpy_array)\n","\n","# e\n","CircleK_type = CircleK_sales.sort_values(by=\"type\", ascending=False)\n","print(CircleK_type)\n","\n","\n","# f\n","circle_fuel_price = CircleK_sales[CircleK_sales[\"fuel_price_usd_per_l\"] > 0.70]\n","print(circle_fuel_price)\n","\n","\n","# g\n","circle_type_hol = CircleK_sales[(CircleK_sales[\"type\"] == \"B\") & (CircleK_sales[\"is_holiday\"] == True)]\n","print(circle_type_hol)\n","\n","\n","# h\n","CircleK_sales[\"amount_of_sales(gallon)\"] = CircleK_sales[\"weekly_sales\"] / CircleK_sales[\"fuel_price_usd_per_l\"]\n","print(CircleK_sales)\n","\n","\n","# i\n","high_sales = CircleK_sales[CircleK_sales[\"amount_of_sales(gallon)\"] > 36000.0]\n","print(high_sales)\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Q10\n","import pandas as pd\n","import re\n","\n","def replace_values(value):\n","    value_str = str(value)\n","    \n","    if re.match(r'^\\d+(\\.\\d+)?\\s*-\\s*\\d+(\\.\\d+)?$', value_str):  # Numerical ranges\n","        return 'RANGE'\n","    elif re.match(r'^-\\d+(\\.\\d+)?$', value_str):  # Negative numbers\n","        return 'NEG'\n","    elif re.match(r'^\\d+\\.\\d+$', value_str):  # Floating numbers\n","        return 'FLOAT'\n","    elif re.match(r'^\\d+$', value_str):  # Numbers\n","        return 'INT'\n","    elif re.match(r'^\\d+(\\.\\d+)?%$', value_str):  # Percentages\n","        return 'PERCENT'\n","    elif re.match(r'^\\d{1,2}-[a-zA-Z]{3}-\\d{4}$', value_str) or re.match(r'^\\d{1,2}\\/\\d{1,2}\\/\\d{4}$', value_str):  # Dates\n","        return 'DATE'\n","    else:\n","        # Replace numbers within a string\n","        value_str = re.sub(r'\\d+(\\.\\d+)?', 'INT', value_str)\n","        return value_str\n","\n","\n","# load the dataset\n","allcovidtables = pd.read_csv('allcovidtables.csv')\n","\n","# applying the replace_values function to all the elements in the DataFrame\n","processed_allcovidtables = allcovidtables.applymap(replace_values)\n","\n","# save to the new CSV\n","processed_allcovidtables.to_csv('processed_allcovidtables.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
